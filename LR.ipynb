{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01285206",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49247da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import roc_auc_score,confusion_matrix, accuracy_score, make_scorer, f1_score,precision_score,recall_score, plot_confusion_matrix\n",
    "from componetes_preprocessamento import RemoveStopWords, Cleaner, Tokenizador, Stemmer, Joiner, pega_resultados, salvando_em_arquivo\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e658ec",
   "metadata": {},
   "source": [
    "## Coleta de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2838a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ee17f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>1</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>1</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>0</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>1</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          order_id  \\\n",
       "0           3  658677c97b385a9be170737859d3511b   \n",
       "1           4  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "2           9  b9bf720beb4ab3728760088589c62129   \n",
       "3          12  9d6f15f95d01e79bd1349cc208361f09   \n",
       "4          15  e51478e7e277a83743b6f9991dbfa3fb   \n",
       "\n",
       "                          review_id  review_score  \\\n",
       "0  e64fb393e7b32834bb789ff8bb30750e             1   \n",
       "1  f7c4243c7fe1938f181bec41a392bdeb             1   \n",
       "2  8670d52e15e00043ae7de4c01cc2fe06             0   \n",
       "3  4b49719c8a200003f700d3d986ea1a19             0   \n",
       "4  3948b09f7c818e2d86c9a546758b2335             1   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a93f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"review_comment_message\"].copy()\n",
    "y = dataset[\"review_score\"].copy()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f011cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 199)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181fb48",
   "metadata": {},
   "source": [
    "## Parâmetros Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a111b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('LR', LogisticRegression(random_state=199))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"LR\", LogisticRegression(random_state=199)),\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0608366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.85      0.79      3208\n",
      "           0       0.57      0.25      0.35      2918\n",
      "           1       0.77      0.92      0.84      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.69      0.67      0.66     12263\n",
      "weighted avg       0.72      0.74      0.71     12263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10883f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc424f5",
   "metadata": {},
   "source": [
    "## Grid Search F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2b5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict()\n",
    "parameters[\"penalty\"] = [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "parameters[\"solver\"] = [\"newton-cg\", \"lbfgs\",\"liblinear\", \"sag\",\"saga\"]\n",
    "parameters[\"C\"] = np.logspace(-4, 4, 20)\n",
    "lrgs = LogisticRegression(random_state=199)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb588cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1800 fits failed out of a total of 4000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.14099489        nan 0.20642619 0.22279624\n",
      " 0.22279624 0.22279624 0.22279624 0.22279624        nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.22279624        nan\n",
      " 0.21461121 0.22279624 0.22279624 0.22279624 0.22279624 0.22279624\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.22279624        nan 0.22279624 0.22279624 0.22279624 0.22279624\n",
      " 0.22279624 0.22279624        nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.22279624        nan 0.22279624 0.29141624\n",
      " 0.29141624 0.23895322 0.2916367  0.29149035        nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.24432919        nan\n",
      " 0.25760328 0.44961179 0.44966604 0.39079355 0.44957846 0.44967872\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.41230849        nan 0.41330218 0.528079   0.528079   0.49596761\n",
      " 0.528079   0.52811277        nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.50909952        nan 0.51790696 0.59322361\n",
      " 0.59322361 0.56007243 0.59322361 0.59322361        nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.57255324        nan\n",
      " 0.59024362 0.63323873 0.63323873 0.61085959 0.63323873 0.6332327\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.61973432        nan 0.62937533 0.64932004 0.64932225 0.63633292\n",
      " 0.64932004 0.64931542        nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.64236954        nan 0.6478919  0.65715781\n",
      " 0.65692336 0.64748389 0.65715781 0.6572782         nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.65074045        nan\n",
      " 0.65560761 0.65761351 0.65628987 0.65103428 0.65761351 0.65761351\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.64520564        nan 0.64892524 0.64992833 0.64945426 0.64762507\n",
      " 0.64992833 0.6498762         nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.63899179        nan 0.64038386 0.64519996\n",
      " 0.64406498 0.64436141 0.64519996 0.64519996        nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.63135528        nan\n",
      " 0.63396237 0.63997803 0.64273406 0.64025941 0.63997803 0.63997959\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.62505843        nan 0.62933746 0.63372808 0.63978062 0.63557217\n",
      " 0.63370667 0.63408287        nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.62174789        nan 0.62774858 0.62814815\n",
      " 0.6393961  0.63055237 0.62830666 0.6295314         nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.61833456        nan\n",
      " 0.62655324 0.62432073 0.63659537 0.62540954 0.62533673 0.6273673\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659        nan        nan\n",
      " 0.61646275        nan 0.62632657 0.62105702 0.6350231  0.62194694\n",
      " 0.62415054 0.62649334        nan        nan        nan        nan\n",
      "        nan 0.61121953 0.63599066        nan 0.62264027 0.62586659\n",
      "        nan        nan 0.61547879        nan 0.62606662 0.61841419\n",
      " 0.63623947 0.61883038 0.62341262 0.62638304        nan        nan\n",
      "        nan        nan        nan 0.61121953 0.63599066        nan\n",
      " 0.62264027 0.62586659        nan        nan 0.61443962        nan\n",
      " 0.6259785  0.61589566 0.63674874 0.61753562 0.62305264 0.62601929\n",
      "        nan        nan        nan        nan        nan 0.61121953\n",
      " 0.63599066        nan 0.62264027 0.62586659]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('GS',\n",
       "                 GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                              estimator=LogisticRegression(random_state=199),\n",
       "                              n_jobs=-1,...\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                          'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                      'none'],\n",
       "                                          'solver': ['newton-cg', 'lbfgs',\n",
       "                                                     'liblinear', 'sag',\n",
       "                                                     'saga']},\n",
       "                              scoring='f1_macro', verbose=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gsf1 = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"GS\", GridSearchCV(lrgs, parameters, scoring=\"f1_macro\", cv=kfold, verbose=1, refit=True,n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "pipeline_gsf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afda684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan {'C': 0.0001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'sag'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "cvres = pipeline_gsf1[\"GS\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8198735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.84      0.79      3208\n",
      "           0       0.55      0.26      0.35      2918\n",
      "           1       0.77      0.92      0.84      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.69      0.67      0.66     12263\n",
      "weighted avg       0.71      0.74      0.71     12263\n",
      "\n",
      "['lr', 'Grid Search', 0.7397863491804616, 0.6595564999430278, 0.68880994411755, 0.6713863077298748, 'f1 score', {'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'newton-cg'}]\n"
     ]
    }
   ],
   "source": [
    "predicted_y_gsf1 = pipeline_gsf1.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y_gsf1))\n",
    "resultado = pega_resultados(\"lr\", \"Grid Search\", y_test, predicted_y_gsf1, \"f1 score\", pipeline_gsf1[\"GS\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa355b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.623776739188721, random_state=199, solver='newton-cg')\n",
      "{'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_gsf1[\"GS\"].best_estimator_)\n",
    "print(pipeline_gsf1[\"GS\"].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a918e68",
   "metadata": {},
   "source": [
    "## Grid Search Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d403db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1800 fits failed out of a total of 4000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.26821851        nan 0.45517296 0.50193982\n",
      " 0.50193982 0.50193982 0.50193982 0.50193982        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.50193982        nan\n",
      " 0.47855639 0.50193982 0.50193982 0.50193982 0.50193982 0.50193982\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.50193982        nan 0.50193982 0.50193982 0.50193982 0.50193982\n",
      " 0.50193982 0.50193982        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.50193982        nan 0.50193982 0.52927197\n",
      " 0.52927197 0.5080214  0.52937683 0.52930692        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.50948946        nan\n",
      " 0.5143128  0.62552922 0.62556417 0.58264339 0.62549427 0.62556417\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.5935482         nan 0.59449188 0.69165754 0.69165754 0.66747107\n",
      " 0.69165754 0.69169249        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.67865542        nan 0.68026325 0.72384765\n",
      " 0.72384765 0.71095068 0.72384765 0.72384765        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.70815452        nan\n",
      " 0.71143998 0.73863232 0.73863232 0.7320614  0.73863232 0.73863232\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.7327953         nan 0.73087319 0.74359548 0.74359548 0.74114877\n",
      " 0.74359548 0.74359548        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.74160322        nan 0.73996046 0.74439943\n",
      " 0.74422464 0.74349055 0.74439943 0.74443437        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.74205764        nan\n",
      " 0.74051965 0.74017021 0.73870223 0.7421275  0.74017021 0.74017021\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.73185167        nan 0.72940506 0.73097784 0.73062839 0.73597595\n",
      " 0.73097784 0.73090794        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.72241467        nan 0.71874497 0.72458178\n",
      " 0.72300895 0.72940504 0.72458178 0.72458178        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.71353708        nan\n",
      " 0.71203416 0.71832552 0.72007314 0.72374291 0.71832552 0.71836049\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.70700109        nan 0.7075952  0.71171968 0.7166827  0.71822055\n",
      " 0.71164977 0.71217403        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.70382051        nan 0.70602241 0.70616225\n",
      " 0.71615846 0.71238363 0.70644185 0.70770013        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.70070985        nan\n",
      " 0.70497389 0.70186316 0.71287282 0.70752528 0.70336608 0.70595252\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992        nan        nan\n",
      " 0.69910204        nan 0.70465935 0.6990322  0.71364171 0.70399516\n",
      " 0.70200296 0.70497389        nan        nan        nan        nan\n",
      "        nan 0.69032909 0.71395643        nan 0.70077968 0.70423992\n",
      "        nan        nan 0.69798361        nan 0.70448459 0.69686513\n",
      " 0.71346709 0.70116409 0.70137386 0.70465935        nan        nan\n",
      "        nan        nan        nan 0.69032909 0.71395643        nan\n",
      " 0.70077968 0.70423992        nan        nan 0.6970399         nan\n",
      " 0.70437973 0.69462817 0.71311767 0.69994077 0.70109425 0.70441468\n",
      "        nan        nan        nan        nan        nan 0.69032909\n",
      " 0.71395643        nan 0.70077968 0.70423992]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('GS',\n",
       "                 GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                              estimator=LogisticRegression(random_state=199),\n",
       "                              n_jobs=-1,...\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                          'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                      'none'],\n",
       "                                          'solver': ['newton-cg', 'lbfgs',\n",
       "                                                     'liblinear', 'sag',\n",
       "                                                     'saga']},\n",
       "                              scoring='accuracy', verbose=1))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gsac = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"GS\", GridSearchCV(lrgs, parameters, scoring=\"accuracy\", cv=kfold, verbose=1, refit=True,n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "pipeline_gsac.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af3afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan {'C': 0.0001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'sag'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "nan {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "cvres = pipeline_gsac[\"GS\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "447f00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.86      0.79      3208\n",
      "           0       0.58      0.24      0.34      2918\n",
      "           1       0.78      0.92      0.84      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.70      0.68      0.66     12263\n",
      "weighted avg       0.72      0.74      0.71     12263\n",
      "\n",
      "['lr', 'Grid Search', 0.744842208268776, 0.6603232654349752, 0.6978910822800519, 0.6754524631491075, 'acuracia', {'C': 0.615848211066026, 'penalty': 'l2', 'solver': 'saga'}]\n"
     ]
    }
   ],
   "source": [
    "predicted_y_gsac = pipeline_gsac.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y_gsac))\n",
    "resultado = pega_resultados(\"lr\", \"Grid Search\", y_test, predicted_y_gsac, \"acuracia\", pipeline_gsac[\"GS\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d4e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.615848211066026, random_state=199, solver='saga')\n",
      "{'C': 0.615848211066026, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_gsac[\"GS\"].best_estimator_)\n",
    "print(pipeline_gsac[\"GS\"].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f08eed",
   "metadata": {},
   "source": [
    "## Randomized Search F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8eea362",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rs = dict()\n",
    "parameters_rs[\"penalty\"] = [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "parameters_rs[\"solver\"] = [\"newton-cg\", \"lbfgs\",\"liblinear\", \"sag\",\"saga\"]\n",
    "parameters_rs[\"C\"] = np.logspace(-8, 8, 40)\n",
    "lrrs = LogisticRegression(random_state=199)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b16d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.63599066 0.63805064 0.65042054        nan 0.64500816 0.46347635\n",
      "        nan 0.61121953        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('RS',\n",
       "                 RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                                    estimator=LogisticRegression(random_state=199),\n",
       "                                    n_jo...\n",
       "       7.01703829e+01, 1.80472177e+02, 4.64158883e+02, 1.19377664e+03,\n",
       "       3.07029063e+03, 7.89652287e+03, 2.03091762e+04, 5.22334507e+04,\n",
       "       1.34339933e+05, 3.45510729e+05, 8.88623816e+05, 2.28546386e+06,\n",
       "       5.87801607e+06, 1.51177507e+07, 3.88815518e+07, 1.00000000e+08]),\n",
       "                                                         'penalty': ['l1', 'l2',\n",
       "                                                                     'elasticnet',\n",
       "                                                                     'none'],\n",
       "                                                         'solver': ['newton-cg',\n",
       "                                                                    'lbfgs',\n",
       "                                                                    'liblinear',\n",
       "                                                                    'sag',\n",
       "                                                                    'saga']},\n",
       "                                    scoring='f1_macro', verbose=1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rsf1 = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"RS\", RandomizedSearchCV(lrrs, parameters_rs, scoring=\"f1_macro\", cv=kfold, verbose=1, refit=True,n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "pipeline_rsf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684d2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan {'solver': 'sag', 'penalty': 'elasticnet', 'C': 6.614740641230146e-08}\n",
      "nan {'solver': 'newton-cg', 'penalty': 'elasticnet', 'C': 6.614740641230146e-08}\n",
      "nan {'solver': 'lbfgs', 'penalty': 'elasticnet', 'C': 10.608183551394482}\n",
      "nan {'solver': 'liblinear', 'penalty': 'elasticnet', 'C': 7896.522868499733}\n",
      "0.6504205403705169 {'solver': 'saga', 'penalty': 'l2', 'C': 4.124626382901348}\n"
     ]
    }
   ],
   "source": [
    "cvres = pipeline_rsf1[\"RS\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8ca9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.83      0.78      3208\n",
      "           0       0.54      0.26      0.35      2918\n",
      "           1       0.77      0.91      0.83      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.68      0.67      0.66     12263\n",
      "weighted avg       0.71      0.74      0.71     12263\n",
      "\n",
      "['lr', 'Randomized Search', 0.7352197667781131, 0.6571509892778424, 0.6837729759095046, 0.6673300028807286, 'f1 score', {'solver': 'saga', 'penalty': 'l2', 'C': 4.124626382901348}]\n"
     ]
    }
   ],
   "source": [
    "predicted_y_rsf1 = pipeline_rsf1.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y_rsf1))\n",
    "resultado = pega_resultados(\"lr\", \"Randomized Search\", y_test, predicted_y_rsf1, \"f1 score\", pipeline_rsf1[\"RS\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c33f9799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4.124626382901348, random_state=199, solver='saga')\n",
      "{'solver': 'saga', 'penalty': 'l2', 'C': 4.124626382901348}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_rsf1[\"RS\"].best_estimator_)\n",
    "print(pipeline_rsf1[\"RS\"].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4f61d",
   "metadata": {},
   "source": [
    "## Randomized Search Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f7bcd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.70151363 0.45517296        nan 0.70423992 0.70423992 0.50193982\n",
      "        nan 0.70423992        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('RS',\n",
       "                 RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                                    estimator=LogisticRegression(random_state=199),\n",
       "                                    n_jo...\n",
       "       7.01703829e+01, 1.80472177e+02, 4.64158883e+02, 1.19377664e+03,\n",
       "       3.07029063e+03, 7.89652287e+03, 2.03091762e+04, 5.22334507e+04,\n",
       "       1.34339933e+05, 3.45510729e+05, 8.88623816e+05, 2.28546386e+06,\n",
       "       5.87801607e+06, 1.51177507e+07, 3.88815518e+07, 1.00000000e+08]),\n",
       "                                                         'penalty': ['l1', 'l2',\n",
       "                                                                     'elasticnet',\n",
       "                                                                     'none'],\n",
       "                                                         'solver': ['newton-cg',\n",
       "                                                                    'lbfgs',\n",
       "                                                                    'liblinear',\n",
       "                                                                    'sag',\n",
       "                                                                    'saga']},\n",
       "                                    scoring='accuracy', verbose=1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_rsac = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"RS\", RandomizedSearchCV(lrrs, parameters_rs, scoring=\"accuracy\", cv=kfold, verbose=1, refit=True,n_jobs=-1)),\n",
    "                    ])\n",
    "\n",
    "pipeline_rsac.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96163e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan {'solver': 'liblinear', 'penalty': 'elasticnet', 'C': 100000000.0}\n",
      "nan {'solver': 'sag', 'penalty': 'l1', 'C': 100000000.0}\n",
      "nan {'solver': 'sag', 'penalty': 'elasticnet', 'C': 1e-08}\n",
      "nan {'solver': 'liblinear', 'penalty': 'none', 'C': 0.0003257020655659783}\n",
      "0.7042399155270365 {'solver': 'saga', 'penalty': 'none', 'C': 7896.522868499733}\n"
     ]
    }
   ],
   "source": [
    "cvres = pipeline_rsac[\"RS\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e93916a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.75      0.74      3208\n",
      "           0       0.46      0.26      0.33      2918\n",
      "           1       0.75      0.89      0.82      6137\n",
      "\n",
      "    accuracy                           0.71     12263\n",
      "   macro avg       0.65      0.64      0.63     12263\n",
      "weighted avg       0.68      0.71      0.68     12263\n",
      "\n",
      "['lr', 'Randomized Search', 0.7065970806491071, 0.6299313535671683, 0.6467160392855865, 0.6361113020490129, 'acuracia', {'solver': 'saga', 'penalty': 'l2', 'C': 888623.8162743407}]\n"
     ]
    }
   ],
   "source": [
    "predicted_y_rsac = pipeline_rsac.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y_rsac))\n",
    "resultado = pega_resultados(\"lr\", \"Randomized Search\", y_test, predicted_y_rsac, \"acuracia\", pipeline_rsac[\"RS\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0479f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=888623.8162743407, random_state=199, solver='saga')\n",
      "{'solver': 'saga', 'penalty': 'l2', 'C': 888623.8162743407}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_rsac[\"RS\"].best_estimator_)\n",
    "print(pipeline_rsac[\"RS\"].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01e60afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "salvando_em_arquivo(\"resultados/LR_resultados.csv\", resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
