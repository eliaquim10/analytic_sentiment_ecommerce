{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49247da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nltk\n",
    "# import re\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import RSLPStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix, accuracy_score, make_scorer, f1_score,precision_score,recall_score, plot_confusion_matrix\n",
    "from componetes_preprocessamento import RemoveStopWords, Cleaner, Tokenizador, Stemmer, Joiner\n",
    "from sklearn.pipeline import Pipeline\n",
    "# nltk.download('rslp')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2838a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ee17f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>1</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>1</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>0</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>1</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          order_id  \\\n",
       "0           3  658677c97b385a9be170737859d3511b   \n",
       "1           4  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "2           9  b9bf720beb4ab3728760088589c62129   \n",
       "3          12  9d6f15f95d01e79bd1349cc208361f09   \n",
       "4          15  e51478e7e277a83743b6f9991dbfa3fb   \n",
       "\n",
       "                          review_id  review_score  \\\n",
       "0  e64fb393e7b32834bb789ff8bb30750e             1   \n",
       "1  f7c4243c7fe1938f181bec41a392bdeb             1   \n",
       "2  8670d52e15e00043ae7de4c01cc2fe06             0   \n",
       "3  4b49719c8a200003f700d3d986ea1a19             0   \n",
       "4  3948b09f7c818e2d86c9a546758b2335             1   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a93f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"review_comment_message\"].copy()\n",
    "y = dataset[\"review_score\"].copy()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f011cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a111b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('LR', LogisticRegression(random_state=199))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"LR\", LogisticRegression(random_state=199)),\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0608366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.85      0.79      3208\n",
      "           0       0.57      0.25      0.35      2918\n",
      "           1       0.77      0.92      0.84      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.69      0.67      0.66     12263\n",
      "weighted avg       0.72      0.74      0.71     12263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d2b5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict()\n",
    "parameters[\"penalty\"] = [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "parameters[\"solver\"] = [\"newton-cg\", \"lbfgs\",\"liblinear\", \"sag\",\"saga\"]\n",
    "parameters[\"C\"] = np.logspace(-4, 4, 20)\n",
    "lrgs = LogisticRegression(random_state=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb588cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1800 fits failed out of a total of 4000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.14099489        nan 0.22279624 0.22279624\n",
      " 0.22279624 0.22279624 0.22279624 0.22279624        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.22279624        nan\n",
      " 0.22279624 0.22279624 0.22279624 0.22279624 0.22279624 0.22279624\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.22279624        nan 0.22279624 0.22279624 0.22279624 0.22279624\n",
      " 0.22279624 0.22279624        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.22279624        nan 0.22279624 0.29115299\n",
      " 0.29115299 0.23903677 0.29107924 0.29115299        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.24426727        nan\n",
      " 0.2574143  0.44969058 0.44969058 0.39019636 0.44969058 0.44976879\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.412621          nan 0.41375189 0.5284753  0.52845469 0.49565527\n",
      " 0.5284753  0.52851618        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.50848191        nan 0.51836122 0.59512578\n",
      " 0.59512578 0.56022187 0.59512578 0.59527687        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.57216651        nan\n",
      " 0.58892417 0.63319868 0.63304028 0.61106092 0.63319868 0.63319588\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.61973561        nan 0.62861329 0.6485568  0.64862799 0.63570321\n",
      " 0.64855901 0.64863704        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.64178786        nan 0.6494795  0.65650796\n",
      " 0.65649135 0.64736819 0.65650796 0.6565225         nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.65041069        nan\n",
      " 0.65596314 0.6567213  0.65636203 0.65272408 0.6567213  0.65675781\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.65006408        nan 0.65011462 0.65255    0.6532846  0.65204589\n",
      " 0.65255    0.65251178        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.64190483        nan 0.63991853 0.645823\n",
      " 0.64784773 0.64898719 0.645823   0.64577638        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.63261102        nan\n",
      " 0.63363794 0.63917955 0.64386416 0.64260642 0.63917955 0.63918692\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.6259001         nan 0.63001746 0.63276793 0.64124663 0.63513257\n",
      " 0.6328412  0.63313762        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.62112793        nan 0.62747259 0.62835775\n",
      " 0.6399089  0.63016839 0.62863617 0.62921422        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.61909911        nan\n",
      " 0.6264877  0.6231298  0.64072167 0.62682088 0.62541339 0.62688623\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548        nan        nan\n",
      " 0.61743141        nan 0.62598968 0.62042175 0.63969315 0.62162336\n",
      " 0.62329926 0.62642362        nan        nan        nan        nan\n",
      "        nan 0.61178017 0.64148996        nan 0.62240109 0.62562548\n",
      "        nan        nan 0.61671587        nan 0.62576016 0.6169778\n",
      " 0.63930124 0.61940177 0.62278457 0.62597146        nan        nan\n",
      "        nan        nan        nan 0.61178017 0.64148996        nan\n",
      " 0.62240109 0.62562548        nan        nan 0.61475437        nan\n",
      " 0.62566826 0.6158014  0.64046077 0.61747976 0.62253641 0.6257299\n",
      "        nan        nan        nan        nan        nan 0.61178017\n",
      " 0.64148996        nan 0.62240109 0.62562548]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', TfidfVectorizer()),\n",
       "                ('GS',\n",
       "                 GridSearchCV(cv=10,\n",
       "                              estimator=LogisticRegression(random_state=199),\n",
       "                              n_jobs=-4,\n",
       "                              param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6...\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                          'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                      'none'],\n",
       "                                          'solver': ['newton-cg', 'lbfgs',\n",
       "                                                     'liblinear', 'sag',\n",
       "                                                     'saga']},\n",
       "                              scoring='f1_macro', verbose=1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", TfidfVectorizer()),\n",
    "                    (\"GS\", GridSearchCV(lrgs, parameters, scoring=\"f1_macro\", cv=10, verbose=1, refit=True,n_jobs=-4)),\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8198735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.84      0.79      3208\n",
      "           0       0.55      0.26      0.35      2918\n",
      "           1       0.77      0.92      0.84      6137\n",
      "\n",
      "    accuracy                           0.74     12263\n",
      "   macro avg       0.69      0.67      0.66     12263\n",
      "weighted avg       0.71      0.74      0.71     12263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa355b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.623776739188721, random_state=199, solver='saga')\n",
      "{'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline[\"GS\"].best_estimator_)\n",
    "print(pipeline[\"GS\"].best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
