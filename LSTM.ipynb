{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HVclb4QSZhl"
      },
      "source": [
        "## LSTM\n",
        "\n"
      ],
      "id": "8HVclb4QSZhl"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49247da",
        "outputId": "43f69b46-ddd8-4f49-87f2-786cd3dce6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix, accuracy_score, make_scorer, f1_score,precision_score,recall_score, plot_confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('rslp')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from argparse import Namespace\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from componetes_preprocessamento import RemoveStopWords, Cleaner, Tokenizador, Stemmer, Joiner, pega_resultados, salvando_em_arquivo\n"
      ],
      "id": "b49247da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e98aiiASiGH"
      },
      "source": [
        "### Coleta de Dados"
      ],
      "id": "4e98aiiASiGH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c647d8cd"
      },
      "outputs": [],
      "source": [
        "args = Namespace(\n",
        "    train_split = 0.7,\n",
        "    random_state = 42,\n",
        "    vocab_size = 10000,\n",
        "    embedding_dim = 16,\n",
        "    max_length = 120,\n",
        "    batch_size=128,\n",
        "    num_epochs=5,\n",
        "    early_stopping_criteria=2,\n",
        "    dropout_p=0.1,\n",
        "    model_storage=\"model_storage/lstm\",\n",
        ")"
      ],
      "id": "c647d8cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2838a06d"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"reviews.csv\")\n",
        "X = dataset[\"review_comment_message\"].copy()\n",
        "y = dataset[\"review_score\"].copy()\n",
        "y = np.array(y)"
      ],
      "id": "2838a06d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1df3681d",
        "outputId": "b9beac28-8859-4e0b-9b12-050a0d8e0ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 ... 0 1 2]\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,len(y)):\n",
        "    if y[i] == -1:\n",
        "        y[i] = 2\n",
        "print(y)"
      ],
      "id": "1df3681d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db5be6cd",
        "outputId": "3aa5bbe1-7556-4d21-e8bc-a1f9edb43152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "[1 1 0 ... 0 1 2]\n"
          ]
        }
      ],
      "source": [
        "y_dummy = np_utils.to_categorical(y)\n",
        "print(y_dummy)\n",
        "print(y)"
      ],
      "id": "db5be6cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2c58e1"
      },
      "source": [
        "## Pré-Processamento"
      ],
      "id": "be2c58e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb37e875"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 199)"
      ],
      "id": "bb37e875"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "803ab284"
      },
      "outputs": [],
      "source": [
        "oov_tok = \"<OOV>\"\n",
        "tokenizer = Tokenizer(num_words = args.vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "def preprocess(training_sentences, testing_sentences, max_length, vocab_size, trunc_type='post', oov_tok = \"<OOV>\"):\n",
        "    \"\"\"\n",
        "    Args\n",
        "        training_sentences\n",
        "        training_labels\n",
        "        testing_sentences\n",
        "        testing_labels\n",
        "    Return\n",
        "        training_sentences\n",
        "        training_labels\n",
        "        testing_sentences\n",
        "        testing_labels \n",
        "    \"\"\"\n",
        "\n",
        "    stopword = stopwords.words(\"portuguese\")\n",
        "    stem = RSLPStemmer()\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    def clear(review):\n",
        "        review = review.lower()\n",
        "        # remove pula de linha \n",
        "        review = re.sub('\\n', ' ', review)        \n",
        "        review = re.sub('\\r', ' ', review)\n",
        "\n",
        "        # remove numero \n",
        "        review = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' #numero ', review)\n",
        "\n",
        "        # remove caracters especiais \n",
        "        review = re.sub(r'R\\$', ' ', review)\n",
        "        review = re.sub(r'\\W', ' ', review)\n",
        "        review = re.sub(r'\\s+', ' ', review)\n",
        "\n",
        "        # remove links \n",
        "        urls = re.findall('(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', review)\n",
        "        if len(urls) > 0:\n",
        "            for url in urls:\n",
        "                for link in url:\n",
        "                    review = review.replace(link, '')\n",
        "            review = review.replace(':', '')\n",
        "            review = review.replace('/', '')\n",
        "        return review\n",
        "\n",
        "    training_sentences = training_sentences.apply(lambda review: clear(review))\n",
        "    testing_sentences = testing_sentences.apply(lambda review: clear(review))\n",
        "    training_sentences = training_sentences.apply(lambda words_review: [word for word in words_review if word not in stopword])\n",
        "    testing_sentences = testing_sentences.apply(lambda words_review: [word for word in words_review if word not in stopword])\n",
        "    training_sentences = training_sentences.apply(lambda words_review: [stem.stem(word) for word in words_review ])\n",
        "    testing_sentences = testing_sentences.apply(lambda words_review: [stem.stem(word) for word in words_review ])\n",
        "    training_sentences = training_sentences.apply(lambda words_review: \" \".join(words_review))\n",
        "    testing_sentences = testing_sentences.apply(lambda words_review: \" \".join(words_review))\n",
        "    training_sentences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "\n",
        "    training_padded = pad_sequences(training_sentences,maxlen=max_length, truncating=trunc_type)\n",
        "    testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "\n",
        "    return training_padded, testing_padded"
      ],
      "id": "803ab284"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fe9848c"
      },
      "outputs": [],
      "source": [
        "X_train_new, X_test_new = preprocess(X_train, X_test, args.max_length, args.vocab_size)"
      ],
      "id": "2fe9848c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87dae4b7"
      },
      "source": [
        "## Parâmetros Padrão"
      ],
      "id": "87dae4b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c16a52e0",
        "outputId": "341cc069-c60e-4f89-bcf9-d3ff6a358bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 16)           160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 120, 16)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 120, 16)           2112      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 120, 16)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 16)                2112      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 164,275\n",
            "Trainable params: 164,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(args.vocab_size, args.embedding_dim, input_length=args.max_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "id": "c16a52e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14b2d391",
        "outputId": "44ae820a-13c3-4467-a895-66b827e8eff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "224/224 [==============================] - 13s 50ms/step - loss: 0.9581 - accuracy: 0.5682\n",
            "Epoch 2/10\n",
            "224/224 [==============================] - 11s 48ms/step - loss: 0.8928 - accuracy: 0.6095\n",
            "Epoch 3/10\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8829 - accuracy: 0.6150\n",
            "Epoch 4/10\n",
            "224/224 [==============================] - 10s 45ms/step - loss: 0.8716 - accuracy: 0.6236\n",
            "Epoch 5/10\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8616 - accuracy: 0.6306\n",
            "Epoch 6/10\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8456 - accuracy: 0.6384\n",
            "Epoch 7/10\n",
            "224/224 [==============================] - 10s 46ms/step - loss: 0.8335 - accuracy: 0.6434\n",
            "Epoch 8/10\n",
            "224/224 [==============================] - 10s 47ms/step - loss: 0.8252 - accuracy: 0.6481\n",
            "Epoch 9/10\n",
            "224/224 [==============================] - 10s 47ms/step - loss: 0.8163 - accuracy: 0.6528\n",
            "Epoch 10/10\n",
            "224/224 [==============================] - 11s 47ms/step - loss: 0.8106 - accuracy: 0.6551\n"
          ]
        }
      ],
      "source": [
        "result = model.fit(X_train_new, y_train, batch_size=128, epochs=10, verbose=1)"
      ],
      "id": "14b2d391"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "436661ef",
        "outputId": "4053352c-bfa4-499e-b953-751b5ffda9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384/384 [==============================] - 4s 9ms/step - loss: 0.7905 - accuracy: 0.6591\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7904999852180481, 0.6591372489929199]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test_new,y_test)"
      ],
      "id": "436661ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf9a6d88",
        "outputId": "155e252c-3808-4dc1-de87-98a40b4fd3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.13933723 0.04754004 0.8131227 ]\n",
            " [0.20462166 0.10067131 0.69470704]\n",
            " [0.3100253  0.34379622 0.34617847]\n",
            " ...\n",
            " [0.19093415 0.06603835 0.7430275 ]\n",
            " [0.18805502 0.7970381  0.01490686]\n",
            " [0.22491296 0.71880877 0.05627837]]\n"
          ]
        }
      ],
      "source": [
        "print(predicted_y)"
      ],
      "id": "bf9a6d88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50c50a39",
        "outputId": "74ab99f7-6bc2-45ae-f326-2a8b7f1db2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2918\n",
            "           1       0.68      0.90      0.78      6137\n",
            "           2       0.62      0.79      0.69      3208\n",
            "\n",
            "    accuracy                           0.66     12263\n",
            "   macro avg       0.43      0.56      0.49     12263\n",
            "weighted avg       0.50      0.66      0.57     12263\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predicted_y = model.predict(X_test_new)\n",
        "predicted_y_transform = [np.argmax(t) for t in predicted_y]\n",
        "print(classification_report(y_test, predicted_y_transform))"
      ],
      "id": "50c50a39"
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = []"
      ],
      "metadata": {
        "id": "93KNBQNItTFe"
      },
      "id": "93KNBQNItTFe",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43bc6f1c"
      },
      "source": [
        "## Gridsearch Accuracy"
      ],
      "id": "43bc6f1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f44cd5e"
      },
      "outputs": [],
      "source": [
        "def createLSTM(activation, neurons):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(args.vocab_size, args.embedding_dim, input_length=args.max_length))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=neurons,activation=activation))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "id": "0f44cd5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43d2a3e9",
        "outputId": "a6df1e0f-fdf4-463b-ca0f-b5fc6e374fe1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "parameters = dict()\n",
        "parameters[\"activation\"] = [\"linear\",\"tanh\"]\n",
        "parameters[\"neurons\"] = [8,16]\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=1)"
      ],
      "id": "43d2a3e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecbcf57b"
      },
      "outputs": [],
      "source": [
        "search = GridSearchCV(estimator=model_lstm, param_grid=parameters, scoring=\"accuracy\", cv=kfold, verbose=1, refit=True,n_jobs=-1)"
      ],
      "id": "ecbcf57b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "688f8c82",
        "outputId": "25392e70-9941-45d5-8855-31d6780f1d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 53ms/step - loss: 0.9845 - accuracy: 0.5380\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8938 - accuracy: 0.6077\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.8828 - accuracy: 0.6179\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.8796 - accuracy: 0.6201\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.8753 - accuracy: 0.6217\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 55ms/step - loss: 0.9903 - accuracy: 0.5412\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9105 - accuracy: 0.6042\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.8946 - accuracy: 0.6083\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.8890 - accuracy: 0.6128\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.8814 - accuracy: 0.6169\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 55ms/step - loss: 1.0014 - accuracy: 0.5300\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9154 - accuracy: 0.5972\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 67ms/step - loss: 0.8971 - accuracy: 0.6098\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.8935 - accuracy: 0.6127\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.8832 - accuracy: 0.6172\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 67ms/step - loss: 1.0313 - accuracy: 0.5025\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 14s 72ms/step - loss: 0.9847 - accuracy: 0.5278\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 66ms/step - loss: 0.9688 - accuracy: 0.5403\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.9526 - accuracy: 0.5603\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.9235 - accuracy: 0.5861\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 12s 54ms/step - loss: 1.3666 - accuracy: 0.5247\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 3.6985 - accuracy: 0.5489\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 14s 70ms/step - loss: 0.9671 - accuracy: 0.5571\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 17s 86ms/step - loss: 0.9609 - accuracy: 0.5609\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 20s 100ms/step - loss: 0.9588 - accuracy: 0.5605\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 22s 97ms/step - loss: 1.0093 - accuracy: 0.5177\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9069 - accuracy: 0.6020\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9286 - accuracy: 0.5955\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9030 - accuracy: 0.6059\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 53ms/step - loss: 0.8919 - accuracy: 0.6081\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 55ms/step - loss: 1.0326 - accuracy: 0.4988\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 58ms/step - loss: 0.9915 - accuracy: 0.5170\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.9691 - accuracy: 0.5456\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.9532 - accuracy: 0.5607\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.9405 - accuracy: 0.5723\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 54ms/step - loss: 1.0112 - accuracy: 0.5089\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9389 - accuracy: 0.5789\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.9073 - accuracy: 0.5961\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.8963 - accuracy: 0.6079\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.8868 - accuracy: 0.6159\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 55ms/step - loss: 1.0441 - accuracy: 0.4979\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 56ms/step - loss: 0.9952 - accuracy: 0.5095\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9376 - accuracy: 0.5715\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9105 - accuracy: 0.6009\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 58ms/step - loss: 0.8927 - accuracy: 0.6094\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 13s 55ms/step - loss: 1.0606 - accuracy: 0.4991\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9980 - accuracy: 0.5127\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 11s 55ms/step - loss: 0.9725 - accuracy: 0.5400\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 1.3840 - accuracy: 0.5479\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 11s 54ms/step - loss: 0.9740 - accuracy: 0.5405\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9958 - accuracy: 0.5299\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9007 - accuracy: 0.6067\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8834 - accuracy: 0.6134\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8765 - accuracy: 0.6191\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8684 - accuracy: 0.6229\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9893 - accuracy: 0.5330\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8965 - accuracy: 0.6087\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8870 - accuracy: 0.6119\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8782 - accuracy: 0.6158\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8721 - accuracy: 0.6199\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 1.0067 - accuracy: 0.5179\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9355 - accuracy: 0.5912\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8990 - accuracy: 0.6079\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8850 - accuracy: 0.6162\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8777 - accuracy: 0.6202\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9866 - accuracy: 0.5317\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8859 - accuracy: 0.6148\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8787 - accuracy: 0.6216\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8710 - accuracy: 0.6240\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8679 - accuracy: 0.6254\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 1.0293 - accuracy: 0.5028\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9625 - accuracy: 0.5581\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9060 - accuracy: 0.6009\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8911 - accuracy: 0.6093\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8837 - accuracy: 0.6152\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 61ms/step - loss: 0.9792 - accuracy: 0.5400\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 1.5675 - accuracy: 0.5623\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9314 - accuracy: 0.5863\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.9229 - accuracy: 0.5895\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.9146 - accuracy: 0.5948\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 61ms/step - loss: 1.0085 - accuracy: 0.5157\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9147 - accuracy: 0.6001\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.9043 - accuracy: 0.6047\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8834 - accuracy: 0.6116\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8796 - accuracy: 0.6153\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 62ms/step - loss: 1.0248 - accuracy: 0.5005\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 1.1997 - accuracy: 0.5576\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.9184 - accuracy: 0.5934\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.8977 - accuracy: 0.6056\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.8908 - accuracy: 0.6098\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 61ms/step - loss: 1.0082 - accuracy: 0.5255\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9963 - accuracy: 0.5506\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9510 - accuracy: 0.5683\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 6182.2197 - accuracy: 0.5560\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9719 - accuracy: 0.5612\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 61ms/step - loss: 1.0292 - accuracy: 0.5002\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9848 - accuracy: 0.5266\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9543 - accuracy: 0.5611\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9350 - accuracy: 0.5759\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 61ms/step - loss: 0.9287 - accuracy: 0.5930\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 59ms/step - loss: 0.9769 - accuracy: 0.5551\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8961 - accuracy: 0.6130\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8892 - accuracy: 0.6146\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8836 - accuracy: 0.6190\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8771 - accuracy: 0.6231\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 59ms/step - loss: 0.9993 - accuracy: 0.5290\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.9066 - accuracy: 0.6104\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8843 - accuracy: 0.6220\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8788 - accuracy: 0.6237\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8765 - accuracy: 0.6248\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 59ms/step - loss: 0.9712 - accuracy: 0.5599\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8958 - accuracy: 0.6120\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8912 - accuracy: 0.6156\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8892 - accuracy: 0.6180\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8818 - accuracy: 0.6199\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 60ms/step - loss: 1.0011 - accuracy: 0.5253\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.9054 - accuracy: 0.6074\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8871 - accuracy: 0.6181\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8803 - accuracy: 0.6212\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8749 - accuracy: 0.6252\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 59ms/step - loss: 0.9727 - accuracy: 0.5543\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8945 - accuracy: 0.6123\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8854 - accuracy: 0.6193\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8815 - accuracy: 0.6221\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8770 - accuracy: 0.6222\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9954 - accuracy: 0.5348\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 14s 68ms/step - loss: 0.9042 - accuracy: 0.6108\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8907 - accuracy: 0.6174\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8857 - accuracy: 0.6193\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8794 - accuracy: 0.6231\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 59ms/step - loss: 0.9767 - accuracy: 0.5578\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8947 - accuracy: 0.6162\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8806 - accuracy: 0.6204\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8735 - accuracy: 0.6259\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8681 - accuracy: 0.6275\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9918 - accuracy: 0.5406\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8965 - accuracy: 0.6131\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8823 - accuracy: 0.6211\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8742 - accuracy: 0.6237\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8720 - accuracy: 0.6260\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 1.0162 - accuracy: 0.5143\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.9093 - accuracy: 0.6078\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8880 - accuracy: 0.6214\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8800 - accuracy: 0.6240\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8704 - accuracy: 0.6278\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 14s 60ms/step - loss: 0.9808 - accuracy: 0.5520\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8944 - accuracy: 0.6137\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 12s 59ms/step - loss: 0.8883 - accuracy: 0.6159\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8793 - accuracy: 0.6221\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 12s 60ms/step - loss: 0.8719 - accuracy: 0.6245\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 62ms/step - loss: 0.9804 - accuracy: 0.5458\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8917 - accuracy: 0.6114\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8822 - accuracy: 0.6185\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 62ms/step - loss: 0.8721 - accuracy: 0.6235\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8670 - accuracy: 0.6253\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9711 - accuracy: 0.5548\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 62ms/step - loss: 0.8867 - accuracy: 0.6155\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8729 - accuracy: 0.6226\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8625 - accuracy: 0.6305\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8526 - accuracy: 0.6329\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 64ms/step - loss: 0.9782 - accuracy: 0.5551\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8882 - accuracy: 0.6122\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8761 - accuracy: 0.6219\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8660 - accuracy: 0.6272\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8633 - accuracy: 0.6301\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 64ms/step - loss: 0.9628 - accuracy: 0.5679\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8871 - accuracy: 0.6143\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8786 - accuracy: 0.6192\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8677 - accuracy: 0.6252\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8630 - accuracy: 0.6275\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9607 - accuracy: 0.5634\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8843 - accuracy: 0.6148\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8759 - accuracy: 0.6223\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8668 - accuracy: 0.6261\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8626 - accuracy: 0.6282\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9993 - accuracy: 0.5321\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 62ms/step - loss: 0.8958 - accuracy: 0.6103\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8788 - accuracy: 0.6190\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8675 - accuracy: 0.6270\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8640 - accuracy: 0.6256\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9673 - accuracy: 0.5592\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8855 - accuracy: 0.6135\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8692 - accuracy: 0.6244\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8624 - accuracy: 0.6280\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8551 - accuracy: 0.6318\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9777 - accuracy: 0.5466\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8857 - accuracy: 0.6163\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8770 - accuracy: 0.6226\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8665 - accuracy: 0.6266\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8600 - accuracy: 0.6285\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9590 - accuracy: 0.5710\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8915 - accuracy: 0.6110\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8818 - accuracy: 0.6163\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8774 - accuracy: 0.6217\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8735 - accuracy: 0.6232\n",
            "Epoch 1/5\n",
            "202/202 [==============================] - 15s 63ms/step - loss: 0.9567 - accuracy: 0.5673\n",
            "Epoch 2/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8855 - accuracy: 0.6171\n",
            "Epoch 3/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8732 - accuracy: 0.6230\n",
            "Epoch 4/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8655 - accuracy: 0.6273\n",
            "Epoch 5/5\n",
            "202/202 [==============================] - 13s 63ms/step - loss: 0.8587 - accuracy: 0.6301\n",
            "Epoch 1/5\n",
            "224/224 [==============================] - 16s 63ms/step - loss: 0.9729 - accuracy: 0.5552\n",
            "Epoch 2/5\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8879 - accuracy: 0.6125\n",
            "Epoch 3/5\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8804 - accuracy: 0.6168\n",
            "Epoch 4/5\n",
            "224/224 [==============================] - 14s 63ms/step - loss: 0.8712 - accuracy: 0.6221\n",
            "Epoch 5/5\n",
            "224/224 [==============================] - 14s 64ms/step - loss: 0.8677 - accuracy: 0.6263\n"
          ]
        }
      ],
      "source": [
        "result = search.fit(X_train_new, y_train)"
      ],
      "id": "688f8c82"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5c5371b",
        "outputId": "19588a79-6894-415d-8cce-7f68547befe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd77e6e5cd0>\n",
            "{'activation': 'tanh', 'neurons': 16}\n"
          ]
        }
      ],
      "source": [
        "best_model = result.best_estimator_\n",
        "print(best_model)\n",
        "print(result.best_params_)\n",
        "predicted_y_gsac = best_model.predict(X_test_new)"
      ],
      "id": "b5c5371b"
    },
    {
      "cell_type": "code",
      "source": [
        "cvres = result.cv_results_\n",
        "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
        "for i in idx_args[:5]:\n",
        "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbeFXWTptwY3",
        "outputId": "53473010-2ec0-411e-a222-cc681e7cfbee"
      },
      "id": "wbeFXWTptwY3",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6304917379706508 {'activation': 'tanh', 'neurons': 16}\n",
            "0.629792693909344 {'activation': 'tanh', 'neurons': 8}\n",
            "0.611931732831537 {'activation': 'linear', 'neurons': 16}\n",
            "0.6042071976416744 {'activation': 'linear', 'neurons': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6e0f75",
        "outputId": "54da3b32-f421-4f8c-f5c8-2bf0c4a34f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2918\n",
            "           1       0.66      0.88      0.75      6137\n",
            "           2       0.57      0.72      0.64      3208\n",
            "\n",
            "    accuracy                           0.63     12263\n",
            "   macro avg       0.41      0.53      0.46     12263\n",
            "weighted avg       0.48      0.63      0.54     12263\n",
            "\n",
            "['lstm', 'Grid Search', 0.6296175487238033, 0.46378319315103894, 0.40967988224660395, 0.5345204218284878, 'Acuracia', {'activation': 'tanh', 'neurons': 16}]\n"
          ]
        }
      ],
      "source": [
        "predicted_y_gsac = best_model.predict(X_test_new)\n",
        "print(classification_report(y_test, predicted_y_gsac))\n",
        "resultado = pega_resultados(\"lstm\", \"Grid Search\", y_test, predicted_y_gsac, \"Acuracia\", result.best_params_)\n",
        "resultados.append(resultado)\n",
        "print(resultado)"
      ],
      "id": "ba6e0f75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95e61431"
      },
      "source": [
        "## Gridsearch F1-Score"
      ],
      "id": "95e61431"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "a09d8372"
      },
      "outputs": [],
      "source": [
        "search_gsf1 = GridSearchCV(estimator=model_lstm, param_grid=parameters, scoring=\"f1_macro\", cv=kfold, verbose=1, refit=True,n_jobs=-1)"
      ],
      "id": "a09d8372"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "acf67e18",
        "outputId": "8de14e48-9276-49db-e9d2-7bb83f61c27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n"
          ]
        }
      ],
      "source": [
        "result_gsf1 = search_gsf1.fit(X_train_new, y_train)"
      ],
      "id": "acf67e18"
    },
    {
      "cell_type": "code",
      "source": [
        "cvres = result_gsf1.cv_results_\n",
        "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
        "for i in idx_args[:5]:\n",
        "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KNJc9H26NDc",
        "outputId": "aec0c7bd-ddaa-4e50-cd8e-970e21225e8e"
      },
      "id": "7KNJc9H26NDc",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4636691352625547 {'activation': 'tanh', 'neurons': 16}\n",
            "0.46025005181015954 {'activation': 'tanh', 'neurons': 8}\n",
            "0.4352616421072371 {'activation': 'linear', 'neurons': 8}\n",
            "0.4202837796353524 {'activation': 'linear', 'neurons': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_gsf1 = result_gsf1.best_estimator_\n",
        "predicted_y_gsf1 = best_model_gsf1.predict(X_test_new)\n",
        "print(classification_report(y_test, predicted_y_gsf1))\n",
        "resultado = pega_resultados(\"lstm\", \"Grid Search\", y_test, predicted_y_gsac, \"F1-Score\", result_gsf1.best_params_)\n",
        "resultados.append(resultado)\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9TFgFQx6XIM",
        "outputId": "4aa01252-2e77-4524-acc0-860345f0d0fb"
      },
      "id": "z9TFgFQx6XIM",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2918\n",
            "           1       0.66      0.88      0.75      6137\n",
            "           2       0.57      0.73      0.64      3208\n",
            "\n",
            "    accuracy                           0.63     12263\n",
            "   macro avg       0.41      0.54      0.46     12263\n",
            "weighted avg       0.48      0.63      0.54     12263\n",
            "\n",
            "['lstm', 'Grid Search', 0.6296175487238033, 0.46378319315103894, 0.40967988224660395, 0.5345204218284878, 'F1-Score', {'activation': 'tanh', 'neurons': 16}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c050bd4b"
      },
      "source": [
        "## Randomized Search Accuracy"
      ],
      "id": "c050bd4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b15b30b"
      },
      "outputs": [],
      "source": [
        "del X_train\n",
        "del X_test\n",
        "del dataset"
      ],
      "id": "7b15b30b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b37a4005",
        "outputId": "3b142d7d-8a7b-4386-dc1a-c03a33e2ebee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "parameters_rs = dict()\n",
        "parameters_rs[\"activation\"] = [\"linear\",\"tanh\"]\n",
        "parameters_rs[\"neurons\"] = [8,16]\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=-1)"
      ],
      "id": "b37a4005"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30954a02"
      },
      "outputs": [],
      "source": [
        "random_search = RandomizedSearchCV(estimator=model_lstm, param_distributions=parameters_rs, scoring=\"accuracy\", cv=kfold, verbose=-1, refit=True,n_jobs=-1)"
      ],
      "id": "30954a02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d47b44",
        "outputId": "e2136d88-cf34-4f34-93dc-82ac4c7600db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n"
          ]
        }
      ],
      "source": [
        "result_random = random_search.fit(X_train_new, y_train)"
      ],
      "id": "65d47b44"
    },
    {
      "cell_type": "code",
      "source": [
        "cvres = result_random.cv_results_\n",
        "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
        "for i in idx_args[:5]:\n",
        "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5APbeNyt4n-",
        "outputId": "f7f4dcac-d8d1-4d5e-d4d8-d6a23f89498b"
      },
      "id": "m5APbeNyt4n-",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6304917623960973 {'neurons': 16, 'activation': 'tanh'}\n",
            "0.628289771771072 {'neurons': 8, 'activation': 'tanh'}\n",
            "0.6146235513573098 {'neurons': 16, 'activation': 'linear'}\n",
            "0.6111278425418487 {'neurons': 8, 'activation': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_random = result_random.best_estimator_\n",
        "predicted_y_rsac = best_model_random.predict(X_test_new)\n",
        "print(classification_report(y_test, predicted_y_rsac))\n",
        "resultado = pega_resultados(\"lstm\", \"Random Search\", y_test, predicted_y_gsac, \"Acuracia\", result_random.best_params_)\n",
        "resultados.append(resultado)\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE8SiIjkvB_M",
        "outputId": "855c454e-82d1-42b3-bc84-d1df13a55cbc"
      },
      "id": "gE8SiIjkvB_M",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.00      0.00      2918\n",
            "           1       0.65      0.90      0.75      6137\n",
            "           2       0.59      0.68      0.63      3208\n",
            "\n",
            "    accuracy                           0.63     12263\n",
            "   macro avg       0.50      0.53      0.46     12263\n",
            "weighted avg       0.54      0.63      0.54     12263\n",
            "\n",
            "['lstm', 'Random Search', 0.6296175487238033, 0.46378319315103894, 0.40967988224660395, 0.5345204218284878, 'Acuracia', {'neurons': 16, 'activation': 'tanh'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized Search F1-Score"
      ],
      "metadata": {
        "id": "nrmBxOqTsigM"
      },
      "id": "nrmBxOqTsigM"
    },
    {
      "cell_type": "code",
      "source": [
        "random_search_f1 = RandomizedSearchCV(estimator=model_lstm, param_distributions=parameters_rs, scoring=\"f1_macro\", cv=kfold, verbose=-1, refit=True,n_jobs=-1)"
      ],
      "metadata": {
        "id": "l_GxSuAKsosD"
      },
      "id": "l_GxSuAKsosD",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_rsf1 = random_search_f1.fit(X_train_new, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHJJNUicuuxw",
        "outputId": "2371bbc9-f193-4d5e-82b9-f178d6d6310a"
      },
      "id": "sHJJNUicuuxw",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cvres = result_rsf1.cv_results_\n",
        "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
        "for i in idx_args[:5]:\n",
        "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu5pSldhu1Dt",
        "outputId": "60da72d0-3e3b-4e20-bb12-e2386f9e2517"
      },
      "id": "yu5pSldhu1Dt",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.463889197679724 {'neurons': 16, 'activation': 'tanh'}\n",
            "0.46219077136016545 {'neurons': 8, 'activation': 'tanh'}\n",
            "0.4207311603986293 {'neurons': 8, 'activation': 'linear'}\n",
            "0.3993150638573066 {'neurons': 16, 'activation': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_random = result_rsf1.best_estimator_\n",
        "print(result_rsf1.best_params_)\n",
        "predicted_y_rs = best_model_random.predict(X_test_new)\n",
        "print(classification_report(y_test, predicted_y_rs))"
      ],
      "metadata": {
        "id": "rb7wWu5Du67_"
      },
      "id": "rb7wWu5Du67_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_rsf1 = result_rsf1.best_estimator_\n",
        "predicted_y_rsf1 = best_model_rsf1 .predict(X_test_new)\n",
        "print(classification_report(y_test, predicted_y_rsf1))\n",
        "resultado = pega_resultados(\"lstm\", \"Random Search\", y_test, predicted_y_gsac, \"F1-Score\",result_rsf1.best_params_)\n",
        "resultados.append(resultado)\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ODYQKepvuGC",
        "outputId": "e55992fc-5daf-4c22-e17f-766086166b41"
      },
      "id": "5ODYQKepvuGC",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00      2918\n",
            "           1       0.64      0.92      0.75      6137\n",
            "           2       0.60      0.64      0.62      3208\n",
            "\n",
            "    accuracy                           0.63     12263\n",
            "   macro avg       0.64      0.52      0.46     12263\n",
            "weighted avg       0.63      0.63      0.54     12263\n",
            "\n",
            "['lstm', 'Random Search', 0.6296175487238033, 0.46378319315103894, 0.40967988224660395, 0.5345204218284878, 'F1-Score', {'neurons': 16, 'activation': 'tanh'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salvando_em_arquivo(\"LSTM_resultados.csv\", resultados)"
      ],
      "metadata": {
        "id": "Re4Tb1Tq7QMc"
      },
      "id": "Re4Tb1Tq7QMc",
      "execution_count": 51,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Cópia de LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}