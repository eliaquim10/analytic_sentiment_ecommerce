{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49247da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cfpc2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix, accuracy_score, make_scorer, f1_score,precision_score,recall_score, plot_confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from argparse import Namespace\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c647d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    train_split = 0.7,\n",
    "    random_state = 42,\n",
    "    vocab_size = 10000,\n",
    "    embedding_dim = 16,\n",
    "    max_length = 120,\n",
    "    batch_size=128,\n",
    "    num_epochs=5,\n",
    "    early_stopping_criteria=2,\n",
    "    dropout_p=0.1,\n",
    "    model_storage=\"model_storage/lstm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2838a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/reviews.csv\")\n",
    "X = dataset[\"review_comment_message\"].copy()\n",
    "y = dataset[\"review_score\"].copy()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df3681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(y)):\n",
    "    if y[i] == -1:\n",
    "        y[i] = 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5be6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[1 1 0 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "y_dummy = np_utils.to_categorical(y)\n",
    "print(y_dummy)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c58e1",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb37e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803ab284",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_tok = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words = args.vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "def preprocess(training_sentences, testing_sentences, max_length, vocab_size, trunc_type='post', oov_tok = \"<OOV>\"):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        training_sentences\n",
    "        training_labels\n",
    "        testing_sentences\n",
    "        testing_labels\n",
    "    Return\n",
    "        training_sentences\n",
    "        training_labels\n",
    "        testing_sentences\n",
    "        testing_labels \n",
    "    \"\"\"\n",
    "\n",
    "    stopword = stopwords.words(\"portuguese\")\n",
    "    stem = RSLPStemmer()\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    def clear(review):\n",
    "        review = review.lower()\n",
    "        # remove pula de linha \n",
    "        review = re.sub('\\n', ' ', review)        \n",
    "        review = re.sub('\\r', ' ', review)\n",
    "\n",
    "        # remove numero \n",
    "        review = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' #numero ', review)\n",
    "\n",
    "        # remove caracters especiais \n",
    "        review = re.sub(r'R\\$', ' ', review)\n",
    "        review = re.sub(r'\\W', ' ', review)\n",
    "        review = re.sub(r'\\s+', ' ', review)\n",
    "\n",
    "        # remove links \n",
    "        urls = re.findall('(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', review)\n",
    "        if len(urls) > 0:\n",
    "            for url in urls:\n",
    "                for link in url:\n",
    "                    review = review.replace(link, '')\n",
    "            review = review.replace(':', '')\n",
    "            review = review.replace('/', '')\n",
    "        return review\n",
    "\n",
    "    training_sentences = training_sentences.apply(lambda review: clear(review))\n",
    "    testing_sentences = testing_sentences.apply(lambda review: clear(review))\n",
    "    training_sentences = training_sentences.apply(lambda words_review: [word for word in words_review if word not in stopword])\n",
    "    testing_sentences = testing_sentences.apply(lambda words_review: [word for word in words_review if word not in stopword])\n",
    "    # training_sentences = training_sentences.apply(lambda review: word_tokenize(review))\n",
    "    # testing_sentences = testing_sentences.apply(lambda review: word_tokenize(review))\n",
    "    training_sentences = training_sentences.apply(lambda words_review: [stem.stem(word) for word in words_review ])\n",
    "    testing_sentences = testing_sentences.apply(lambda words_review: [stem.stem(word) for word in words_review ])\n",
    "    training_sentences = training_sentences.apply(lambda words_review: \" \".join(words_review))\n",
    "    testing_sentences = testing_sentences.apply(lambda words_review: \" \".join(words_review))\n",
    "    training_sentences = tokenizer.texts_to_sequences(training_sentences)\n",
    "    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "\n",
    "    training_padded = pad_sequences(training_sentences,maxlen=max_length, truncating=trunc_type)\n",
    "    testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
    "\n",
    "    # training_padded = vectorizer.fit_transform(training_sentences)\n",
    "    # testing_padded = vectorizer.fit_transform(testing_sequences)\n",
    "\n",
    "    return training_padded, testing_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe9848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new = preprocess(X_train, X_test, args.max_length, args.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72f5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     input = tf.keras.Input(shape=(args.max_length))\n",
    "#     x = tf.keras.layers.Embedding(args.vocab_size, args.embedding_dim, input_length=args.max_length)(input)\n",
    "\n",
    "#     x = tf.keras.layers.LSTM(16, return_sequences=True)(x)\n",
    "#     x = tf.keras.layers.LSTM(16, return_sequences=True)(x)\n",
    "#     x = tf.keras.layers.LSTM(16)(x)\n",
    "\n",
    "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "#     x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "#     output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "#     return tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dae4b7",
   "metadata": {},
   "source": [
    "## Parâmetros Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16a52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120, 16)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 120, 16)           2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 120, 16)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,275\n",
      "Trainable params: 164,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(args.vocab_size, args.embedding_dim, input_length=args.max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(32,activation=\"linear\"))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b2d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "224/224 [==============================] - 13s 50ms/step - loss: 0.9581 - accuracy: 0.5682\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 11s 48ms/step - loss: 0.8928 - accuracy: 0.6095\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 10s 46ms/step - loss: 0.8829 - accuracy: 0.6150\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 10s 45ms/step - loss: 0.8716 - accuracy: 0.6236\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 10s 46ms/step - loss: 0.8616 - accuracy: 0.6306\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 10s 46ms/step - loss: 0.8456 - accuracy: 0.6384\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 10s 46ms/step - loss: 0.8335 - accuracy: 0.6434\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 10s 47ms/step - loss: 0.8252 - accuracy: 0.6481\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 10s 47ms/step - loss: 0.8163 - accuracy: 0.6528\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 11s 47ms/step - loss: 0.8106 - accuracy: 0.6551\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(X_train_new, y_train, batch_size=128, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436661ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 9ms/step - loss: 0.7905 - accuracy: 0.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7904999852180481, 0.6591372489929199]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf9a6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13933723 0.04754004 0.8131227 ]\n",
      " [0.20462166 0.10067131 0.69470704]\n",
      " [0.3100253  0.34379622 0.34617847]\n",
      " ...\n",
      " [0.19093415 0.06603835 0.7430275 ]\n",
      " [0.18805502 0.7970381  0.01490686]\n",
      " [0.22491296 0.71880877 0.05627837]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c50a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2918\n",
      "           1       0.68      0.90      0.78      6137\n",
      "           2       0.62      0.79      0.69      3208\n",
      "\n",
      "    accuracy                           0.66     12263\n",
      "   macro avg       0.43      0.56      0.49     12263\n",
      "weighted avg       0.50      0.66      0.57     12263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = model.predict(X_test_new)\n",
    "predicted_y_transform = [np.argmax(t) for t in predicted_y]\n",
    "# y_test_transform = [np.argmax(t) for t in y_test]\n",
    "print(classification_report(y_test, predicted_y_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "685f3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=args.early_stopping_criteria)\n",
    "\n",
    "# model = create_model()\n",
    "# model.compile(\n",
    "#   loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "#   optimizer= tf.keras.optimizers.Adam(\n",
    "#     learning_rate=0.0001),\n",
    "#   metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train_new,\n",
    "#     np.array(y_train), \n",
    "#     epochs=15,\n",
    "#     batch_size=args.batch_size,\n",
    "#     callbacks= [earlyStoppingCallback],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4f79f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test_new, np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc6f1c",
   "metadata": {},
   "source": [
    "## Gridsearch Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f44cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTM(activation, neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(args.vocab_size, args.embedding_dim, input_length=args.max_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=neurons,activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(units=neurons,activation=activation))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(units=neurons,activation=activation))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # model.fit(X_train_new, y_train, batch_size=128, epochs=5)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d2a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\AppData\\Local\\Temp/ipykernel_472/1504823002.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "parameters = dict()\n",
    "# parameters[\"epochs\"] = [5,10]\n",
    "parameters[\"activation\"] = [\"linear\",\"relu\"]\n",
    "parameters[\"neurons\"] = [16,32]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecbcf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(estimator=model_lstm, param_grid=parameters, scoring=\"accuracy\", cv=kfold, verbose=1, refit=True,n_jobs=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688f8c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Epoch 1/5\n",
      "224/224 [==============================] - 6s 24ms/step - loss: 0.9657 - accuracy: 0.5549\n",
      "Epoch 2/5\n",
      "224/224 [==============================] - 6s 25ms/step - loss: 0.8898 - accuracy: 0.6107\n",
      "Epoch 3/5\n",
      "224/224 [==============================] - 5s 24ms/step - loss: 0.8790 - accuracy: 0.6179\n",
      "Epoch 4/5\n",
      "224/224 [==============================] - 5s 24ms/step - loss: 0.8699 - accuracy: 0.6249\n",
      "Epoch 5/5\n",
      "224/224 [==============================] - 5s 24ms/step - loss: 0.8650 - accuracy: 0.6255\n"
     ]
    }
   ],
   "source": [
    "result = search.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c5371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = result.best_estimator_\n",
    "predicted_y_gs = best_model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6e0f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 1 2]\n",
      "[0 2 2 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_y_gs)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47852e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.00      0.00      2918\n",
      "           1       0.68      0.84      0.75      6137\n",
      "           2       0.53      0.78      0.64      3208\n",
      "\n",
      "    accuracy                           0.62     12263\n",
      "   macro avg       0.60      0.54      0.46     12263\n",
      "weighted avg       0.62      0.62      0.54     12263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicted_y_gs_transform = [np.argmax(t) for t in predicted_y_gs]\n",
    "# y_test_transform = [np.argmax(t) for t in y_test]\n",
    "print(classification_report(y_test, predicted_y_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e61431",
   "metadata": {},
   "source": [
    "## Gridsearch F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09d8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_gsf1 = GridSearchCV(estimator=model_lstm, param_grid=parameters, scoring=\"f1_macro\", cv=kfold, verbose=1, refit=True,n_jobs=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf67e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Epoch 1/5\n",
      "224/224 [==============================] - 17s 70ms/step - loss: 0.9929 - accuracy: 0.5268\n",
      "Epoch 2/5\n",
      "224/224 [==============================] - 9s 41ms/step - loss: 0.8941 - accuracy: 0.6104\n",
      "Epoch 3/5\n",
      "224/224 [==============================] - 9s 42ms/step - loss: 0.8767 - accuracy: 0.6188\n",
      "Epoch 4/5\n",
      "224/224 [==============================] - 9s 41ms/step - loss: 0.8714 - accuracy: 0.6228\n",
      "Epoch 5/5\n",
      "224/224 [==============================] - 9s 42ms/step - loss: 0.9430 - accuracy: 0.5701\n"
     ]
    }
   ],
   "source": [
    "result_gsf1 = search_gsf1.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aefcfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_gsf1 = result_gsf1.best_estimator_\n",
    "predicted_y_gsf1 = best_model_gsf1.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d7dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2918\n",
      "           1       0.63      0.90      0.74      6137\n",
      "           2       0.57      0.64      0.60      3208\n",
      "\n",
      "    accuracy                           0.62     12263\n",
      "   macro avg       0.40      0.51      0.45     12263\n",
      "weighted avg       0.47      0.62      0.53     12263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_y_gsf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050bd4b",
   "metadata": {},
   "source": [
    "## Randomized Search Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b15b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_test\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37a4005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\AppData\\Local\\Temp/ipykernel_3156/167769438.py:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "parameters_rs = dict()\n",
    "# parameters_rs[\"epochs\"] = [5,10]\n",
    "parameters_rs[\"activation\"] = [\"linear\",\"relu\"]\n",
    "parameters_rs[\"neurons\"] = [8,16]\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "model_lstm = KerasClassifier(build_fn=createLSTM, epochs=5, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30954a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=model_lstm, param_distributions=parameters_rs, scoring=\"accuracy\", cv=kfold, verbose=1, refit=True,n_jobs=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d47b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfpc2\\anaconda3\\envs\\rv_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "result_random = random_search.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83507874",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_random = result_random.best_estimator_\n",
    "predicted_y_rs = best_model_random.predict(X_test_new)\n",
    "print(classification_report(y_test, predicted_y_rs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
