{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede2ce1c",
   "metadata": {},
   "source": [
    "# Coleta de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4a1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - image das etapas(arquitetura) -> ok \n",
    "# - definicao das etapas do que vai ser feito e o que vai ser feito (trello) -> ok\n",
    "\n",
    "# - descricao dos trabalhos relacionados encontrados -> ok\n",
    "\n",
    "# - publicacoes eniac e bracis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca3bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\emn3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emn3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nltk\n",
    "# import re\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import RSLPStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split \n",
    "# nltk.download('rslp')\n",
    "# nltk.download('stopwords')\n",
    "from  componetes_preprocessamento import RemoveStopWords, Cleaner, Tokenizador, Stemmer, Joiner, pega_resultados, salvando_em_arquivo\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a202cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install nltk\n",
    "# import nltk\n",
    "# nltk.download_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39e4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc050296",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a28142",
   "metadata": {},
   "source": [
    "## Definindo Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0d9674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>1</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>1</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>0</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>9d6f15f95d01e79bd1349cc208361f09</td>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>e51478e7e277a83743b6f9991dbfa3fb</td>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>1</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          order_id  \\\n",
       "0           3  658677c97b385a9be170737859d3511b   \n",
       "1           4  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "2           9  b9bf720beb4ab3728760088589c62129   \n",
       "3          12  9d6f15f95d01e79bd1349cc208361f09   \n",
       "4          15  e51478e7e277a83743b6f9991dbfa3fb   \n",
       "\n",
       "                          review_id  review_score  \\\n",
       "0  e64fb393e7b32834bb789ff8bb30750e             1   \n",
       "1  f7c4243c7fe1938f181bec41a392bdeb             1   \n",
       "2  8670d52e15e00043ae7de4c01cc2fe06             0   \n",
       "3  4b49719c8a200003f700d3d986ea1a19             0   \n",
       "4  3948b09f7c818e2d86c9a546758b2335             1   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50198f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"review_comment_message\"].copy()\n",
    "y = dataset[\"review_score\"].copy()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99085bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 199)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c54f6d",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fa3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fb76b",
   "metadata": {},
   "source": [
    "### Accuracy - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ec847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', CountVectorizer()),\n",
       "                ('MNB',\n",
       "                 GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                              estimator=MultinomialNB(), n_jobs=-1,\n",
       "                              param_grid={'alpha':...\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09]),\n",
       "                                          'fit_prior': [False, True]},\n",
       "                              scoring='accuracy'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "parametros = {\n",
    "    \"fit_prior\": [False, True],\n",
    "    \"alpha\": np.arange(.0, 1.1, .01)\n",
    "}\n",
    "kfold = StratifiedKFold(10,shuffle=True, random_state=1)\n",
    "acc_gs_pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", CountVectorizer()),\n",
    "                    (\"MNB\", GridSearchCV(modelo, parametros, scoring=\"accuracy\", cv=kfold, n_jobs=-1)),\n",
    "                    ])\n",
    "acc_gs_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a485d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7253155706602517 {'alpha': 1.08, 'fit_prior': True}\n",
      "0.7252806178465502 {'alpha': 1.09, 'fit_prior': True}\n",
      "0.725280605633827 {'alpha': 1.07, 'fit_prior': True}\n",
      "0.725280605633827 {'alpha': 1.06, 'fit_prior': True}\n",
      "0.7252107122191471 {'alpha': 0.92, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "cvres = acc_gs_pipeline[\"MNB\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34790ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mnb', 'Grid Search', 0.7299192693468156, 0.6581404909642637, 0.6819187841228379, 0.6624766255660014, 'acurracia', {'alpha': 1.08, 'fit_prior': True}]\n"
     ]
    }
   ],
   "source": [
    "y_pred = acc_gs_pipeline.predict(X_test)\n",
    "resultado = pega_resultados(\"mnb\", \"Grid Search\", y_test, y_pred, \"acurracia\", acc_gs_pipeline[\"MNB\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fb76b",
   "metadata": {},
   "source": [
    "### F1 Score - GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ec847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', CountVectorizer()),\n",
       "                ('MNB',\n",
       "                 GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "                              estimator=MultinomialNB(), n_jobs=-1,\n",
       "                              param_grid={'alp...\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09]),\n",
       "                                          'fit_prior': [False, True]},\n",
       "                              scoring='f1_macro'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "parametros = {\n",
    "    \"fit_prior\": [False, True],\n",
    "    \"alpha\": np.arange(.0, 1.1, .01)\n",
    "}\n",
    "kfold = StratifiedKFold(10)\n",
    "f1_gs_pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", CountVectorizer()),\n",
    "                    (\"MNB\", GridSearchCV(modelo, parametros, scoring=\"f1_macro\", cv=kfold, n_jobs=-1)),\n",
    "                    ])\n",
    "f1_gs_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a485d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6623775620930415 {'alpha': 0.28, 'fit_prior': False}\n",
      "0.662320223798129 {'alpha': 0.29, 'fit_prior': False}\n",
      "0.6622918138935106 {'alpha': 0.27, 'fit_prior': False}\n",
      "0.6622534928463722 {'alpha': 0.26, 'fit_prior': False}\n",
      "0.6622491866253623 {'alpha': 0.31, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "cvres = f1_gs_pipeline[\"MNB\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34790ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mnb', 'Grid Search', 0.716464160482753, 0.6628304413922802, 0.6661534839172297, 0.6657296070451265, 'f1 score', {'alpha': 0.28, 'fit_prior': False}]\n"
     ]
    }
   ],
   "source": [
    "y_pred = f1_gs_pipeline.predict(X_test)\n",
    "resultado = pega_resultados(\"mnb\", \"Grid Search\", y_test, y_pred, \"f1 score\", f1_gs_pipeline[\"MNB\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fb76b",
   "metadata": {},
   "source": [
    "### Accuracy - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99ec847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', CountVectorizer()),\n",
       "                ('MNB',\n",
       "                 RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "                                    estimator=MultinomialNB(), n_jobs=-1,\n",
       "                                    param_dist...\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09]),\n",
       "                                                         'fit_prior': [False,\n",
       "                                                                       True]},\n",
       "                                    scoring='f1_macro'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "parametros = {\n",
    "    \"fit_prior\": [False, True],\n",
    "    \"alpha\": np.arange(.0, 1.1, .01)\n",
    "}\n",
    "kfold = StratifiedKFold(10)\n",
    "acc_rs_pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", CountVectorizer()),\n",
    "                    (\"MNB\", RandomizedSearchCV(modelo, parametros, scoring=\"f1_macro\", cv=kfold, n_jobs=-1)),\n",
    "                    ])\n",
    "acc_rs_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a485d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6617666600406571 {'fit_prior': False, 'alpha': 0.43}\n",
      "0.6615536904963093 {'fit_prior': False, 'alpha': 0.63}\n",
      "0.6615509843052335 {'fit_prior': False, 'alpha': 1.05}\n",
      "0.6614271534012616 {'fit_prior': False, 'alpha': 0.51}\n",
      "0.6613371572864596 {'fit_prior': False, 'alpha': 1.04}\n"
     ]
    }
   ],
   "source": [
    "cvres = acc_rs_pipeline[\"MNB\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34790ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mnb', 'Randomized Search', 0.7178504444263231, 0.6637466424296652, 0.6674642642913321, 0.6668492928324167, 'acuracia', {'fit_prior': False, 'alpha': 0.43}]\n"
     ]
    }
   ],
   "source": [
    "y_pred = acc_rs_pipeline.predict(X_test)\n",
    "resultado = pega_resultados(\"mnb\", \"Randomized Search\", y_test, y_pred, \"acuracia\", acc_rs_pipeline[\"MNB\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fb76b",
   "metadata": {},
   "source": [
    "### F1 Score - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99ec847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Cleaner', Cleaner()),\n",
       "                ('Tokenizador', Tokenizador(lingua='portuguese')),\n",
       "                ('RemoveStopWords', RemoveStopWords(lingua='portuguese')),\n",
       "                ('Stemmer', Stemmer()), ('Joiner', Joiner()),\n",
       "                ('Tfidf', CountVectorizer()),\n",
       "                ('MNB',\n",
       "                 RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "                                    estimator=MultinomialNB(), n_jobs=-1,\n",
       "                                    param_dist...\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09]),\n",
       "                                                         'fit_prior': [False,\n",
       "                                                                       True]},\n",
       "                                    scoring='f1_macro'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "parametros = {\n",
    "    \"fit_prior\": [False, True],\n",
    "    \"alpha\": np.arange(.0, 1.1, .01)\n",
    "}\n",
    "kfold = StratifiedKFold(10)\n",
    "f1_rs_pipeline = Pipeline([(\"Cleaner\", Cleaner()), \n",
    "                    (\"Tokenizador\", Tokenizador(\"portuguese\")), \n",
    "                    (\"RemoveStopWords\", RemoveStopWords(\"portuguese\")), \n",
    "                    (\"Stemmer\", Stemmer()), \n",
    "                    (\"Joiner\", Joiner()),\n",
    "                    (\"Tfidf\", CountVectorizer()),\n",
    "                    (\"MNB\", RandomizedSearchCV(modelo, parametros, scoring=\"f1_macro\", cv=kfold, n_jobs=-1)),\n",
    "                    ])\n",
    "f1_rs_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a485d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6621554852065702 {'fit_prior': False, 'alpha': 0.21}\n",
      "0.6618319649715014 {'fit_prior': False, 'alpha': 0.77}\n",
      "0.6617660023170305 {'fit_prior': False, 'alpha': 0.38}\n",
      "0.6614447024191229 {'fit_prior': False, 'alpha': 0.5700000000000001}\n",
      "0.6613371572864596 {'fit_prior': False, 'alpha': 1.04}\n"
     ]
    }
   ],
   "source": [
    "cvres = f1_rs_pipeline[\"MNB\"].cv_results_\n",
    "idx_args = np.argsort(cvres[\"mean_test_score\"])[::-1]\n",
    "for i in idx_args[:5]:\n",
    "    print(cvres[\"mean_test_score\"][i], cvres[\"params\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34790ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mnb', 'Randomized Search', 0.7160564299111147, 0.6625124357075344, 0.6656240803683947, 0.665389826962964, 'f1 score', {'fit_prior': False, 'alpha': 0.43}]\n"
     ]
    }
   ],
   "source": [
    "y_pred = f1_rs_pipeline.predict(X_test)\n",
    "resultado = pega_resultados(\"mnb\", \"Randomized Search\", y_test, y_pred, \"f1 score\", acc_rs_pipeline[\"MNB\"].best_params_)\n",
    "resultados.append(resultado)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02e3e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "salvando_em_arquivo(\"resultados/MNB_resultados.csv\", resultados)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f6ca866bada2297d8fd83be4f6138ccbd7745b9651ccd132432817d094bcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
